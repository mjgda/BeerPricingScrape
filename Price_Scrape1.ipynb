{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from selenium import webdriver\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 14, 14]\n",
      "[26, 26, 26]\n",
      "[10, 10, 10]\n",
      "[6, 6, 6]\n",
      "[8, 8, 8]\n",
      "[21, 21, 21]\n",
      "[26, 26, 26]\n",
      "[14, 14, 14]\n",
      "[14, 14, 14]\n",
      "[30, 30, 30]\n",
      "[29, 29, 29]\n",
      "[1, 1, 1]\n",
      "[6, 6, 6]\n",
      "[19, 19, 19]\n",
      "[20, 20, 20]\n",
      "[23, 23, 23]\n",
      "[13, 13, 13]\n",
      "[18, 18, 18]\n",
      "[27, 27, 27]\n",
      "[28, 28, 28]\n",
      "[2, 2, 2]\n",
      "[6, 6, 6]\n",
      "[9, 9, 9]\n",
      "[17, 17, 17]\n",
      "[26, 26, 26]\n",
      "[14, 14, 14]\n",
      "[15, 15, 15]\n",
      "[30, 30, 30]\n",
      "[24, 24, 24]\n",
      "[3, 3, 3]\n",
      "[6, 6, 6]\n",
      "[11, 11, 11]\n",
      "[13, 13, 13]\n",
      "[22, 22, 22]\n",
      "[18, 18, 18]\n",
      "[20, 20, 20]\n",
      "[29, 29, 29]\n",
      "[34, 34, 34]\n",
      "[1, 1, 1]\n",
      "[7, 7, 7]\n",
      "[12, 12, 12]\n",
      "[23, 23, 23]\n",
      "[25, 25, 25]\n",
      "[16, 16, 16]\n",
      "[19, 19, 19]\n",
      "[27, 27, 27]\n",
      "[27, 27, 27]\n",
      "[4, 4, 4]\n",
      "[6, 6, 6]\n",
      "[13, 13, 13]\n",
      "[20, 20, 20]\n",
      "[24, 24, 24]\n",
      "[13, 13, 13]\n",
      "[18, 18, 18]\n",
      "[12, 12, 12]\n",
      "[28, 28, 28]\n",
      "[7, 7, 7]\n",
      "[5, 5, 5]\n",
      "[4, 4, 4]\n",
      "[21, 21, 21]\n",
      "[23, 23, 23]\n",
      "[10, 10, 10]\n",
      "[19, 19, 19]\n",
      "[22, 22, 22]\n",
      "[29, 29, 29]\n",
      "[0, 0, 0]\n",
      "[5, 5, 5]\n",
      "[5, 5, 5]\n",
      "[15, 15, 15]\n",
      "[26, 26, 26]\n",
      "[12, 12, 12]\n",
      "[12, 12, 12]\n",
      "[15, 15, 15]\n",
      "[15, 15, 15]\n",
      "[0, 0, 0]\n",
      "[3, 3, 3]\n",
      "[3, 3, 3]\n",
      "[14, 14, 14]\n",
      "[26, 26, 26]\n",
      "[10, 10, 10]\n",
      "[17, 17, 17]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##HEB\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    " \n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "#driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe')\n",
    "\n",
    "\n",
    "mlookup={\"angelo\":\"San Angelo\",\"htx\":\"Houston\",\"sa\":\"San Antonio\",\"atx\":\"Austin\",\"cc\":\"Corpus Christi\",\"colleges\":\"College Station\",\"waco\":\"Waco\",\"victoria\":\"Victoria\",\"mcallen\":\"McAllen\"}\n",
    "\n",
    "def hebscrape(market):\n",
    "    login=market+\"price31415@gmail.com\"\n",
    "    pw=market+\"price31415!!\"\n",
    "    \n",
    "    #driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "    driver.get(\"https://www.heb.com/my-account/login?originalURL=https%3A%2F%2Fwww.heb.com%2Fmy-account%2Fdash-board\")\n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"email\"]').send_keys(login)\n",
    "    driver.find_element_by_xpath('//*[@id=\"password\"]').send_keys(pw)\n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"loginForm\"]/form/div[4]/div/button/span').click()\n",
    "    WebDriverWait(driver, 600).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"root\"]/header/div[1]/div[2]/div[1]/form/div/input')))\n",
    "    \n",
    "    \n",
    "                       \n",
    "    brizand=(\"Karbach\",\"Shiner\",\"Deep Ellum\",\"Blue Moon\",\"Saint Arnold\",\"Corona\",\"Michelob Ultra\",\"Truly\",\"White Claw\")\n",
    "    summary=list()\n",
    "    \n",
    "    for b in brizand:\n",
    "        suburl=\"https://www.heb.com/search/?q=\"+b+\"+beer\"\n",
    "        driver.get(suburl)\n",
    "        time.sleep(7)\n",
    "        #WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"footer\"]/div[3]/footer/div/div[1]/div[1]/ul/li[1]/a')))\n",
    "        \n",
    "        \n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "        if len(soup.find_all(class_='sc-ztn198-0 iNjBgW sc-cltr8j-0 kvqfRY'))>0:\n",
    "            product= soup.find_all(class_='sc-ztn198-0 iNjBgW sc-cltr8j-0 kvqfRY')\n",
    "            \n",
    "            \n",
    "            price=[]\n",
    "            pkg= []\n",
    "            brand=[]\n",
    "            for i in product:\n",
    "                try:\n",
    "\n",
    "                    title=str(re.findall(rf'aria-label=\\\"{b}.+?each\\.',str(i))[0])\n",
    "                    title=title[12:]\n",
    "                    title=title.split(',')\n",
    "                    \n",
    "                    brand.append(title[0])\n",
    "                    price.append(title[1][:-5].strip())\n",
    "                    \n",
    "                    \n",
    "                    title2=str(re.findall(rf'alt=\\\"{b}.+?\\\"',str(i))[0])\n",
    "                    title2=title2.split(',')\n",
    "                    pkg.append(title2[1][1:])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "\n",
    "        else:\n",
    "            price_selector = soup.find_all(class_='cat-price-number')\n",
    "            product= soup.find_all(class_='responsivegriditem product-grid-large-fifth product-grid-small-6')\n",
    "\n",
    "            if len(product)==0:\n",
    "                product= soup.find_all(class_='ztn198-0 gIcCcD cltr8j-0 jfvaNx')\n",
    "\n",
    "\n",
    "            price=[]\n",
    "            for i in price_selector:\n",
    "                price.append(str(re.findall(r'\\$[0-9.]*',str(i))[0]))\n",
    "\n",
    "            pkg= []\n",
    "            brand=[]\n",
    "            for i in product:\n",
    "                L=len(str(re.findall(rf'aria-label=\\\"{b}.*[^\\$]',str(i))))\n",
    "                brand.append(str(re.findall(rf'aria-label=\\\"{b}.*[^\\$]',str(i)))[14:L-6])\n",
    "                L=len(str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i))))\n",
    "                tes=str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i)))[L-8:L-2]\n",
    "\n",
    "                if tes[0]!='t':\n",
    "                    pkg.append(str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i)))[L-8:L-2])\n",
    "                else:\n",
    "                    pkg.append(str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i)))[L-7:L-2])\n",
    "\n",
    "                   \n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "        for i in range(len(pkg)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"HEB\",\"market\":mlookup[market],\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "\n",
    "    driver.close()\n",
    "    return summary\n",
    "         \n",
    "\n",
    "#cities=[\"San Angelo\",\"Houston\",\"San Antonio\",\"Austin\",\"Corpus Christi\",\"College Station\",\"Waco\",\"Victoria\",\"Mcallen\"]\n",
    "cities=[\"angelo\",\"htx\",\"sa\",\"atx\",\"cc\",\"colleges\",\"waco\",\"victoria\",\"mcallen\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(hebscrape(i))\n",
    "\n",
    "\n",
    "filename=Current_Date+\"heb.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 46, 46]\n",
      "[58, 58, 58]\n",
      "[21, 21, 21]\n",
      "[11, 11, 11]\n",
      "[35, 35, 35]\n",
      "[24, 24, 24]\n",
      "[28, 28, 28]\n",
      "[29, 29, 29]\n",
      "[21, 21, 21]\n",
      "[43, 43, 43]\n",
      "[54, 54, 54]\n",
      "[18, 18, 18]\n",
      "[9, 9, 9]\n",
      "[36, 36, 36]\n",
      "[25, 25, 25]\n",
      "[21, 21, 21]\n",
      "[33, 33, 33]\n",
      "[27, 27, 27]\n",
      "[25, 25, 25]\n",
      "[45, 45, 45]\n",
      "[24, 24, 24]\n",
      "[12, 12, 12]\n",
      "[30, 30, 30]\n",
      "[22, 22, 22]\n",
      "[23, 23, 23]\n",
      "[32, 32, 32]\n",
      "[24, 24, 24]\n",
      "[45, 45, 45]\n",
      "[49, 49, 49]\n",
      "[15, 15, 15]\n",
      "[11, 11, 11]\n",
      "[60, 60, 60]\n",
      "[30, 30, 30]\n",
      "[30, 30, 30]\n",
      "[27, 27, 27]\n",
      "[20, 20, 20]\n",
      "[42, 42, 42]\n",
      "[47, 47, 47]\n",
      "[17, 17, 17]\n",
      "[9, 9, 9]\n",
      "[23, 23, 23]\n",
      "[30, 30, 30]\n",
      "[27, 27, 27]\n",
      "[30, 30, 30]\n",
      "[21, 21, 21]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Total Wine\n",
    "\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def twscrape(market):\n",
    "    \n",
    "    def hoverclick(xxpath):\n",
    "        hover = ActionChains(driver).move_to_element(driver.find_element_by_xpath(xxpath))\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "\n",
    "        tries=0\n",
    "        while tries<3:\n",
    "            try:\n",
    "                hover.perform()\n",
    "                break\n",
    "            except:\n",
    "                tries+=1\n",
    "        time.sleep(2)\n",
    "        \n",
    "        action.click()\n",
    "        action.perform()\n",
    "    \n",
    "    url=\"https://www.totalwine.com/store-finder/search?q=\"+market.replace(\" \",\"%20\")+\"&radius=15\"\n",
    "    driver.get(url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "    try:\n",
    "        hoverclick('/html/body/div[9]/div[2]/div/button')\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        time.sleep(2)\n",
    "    \n",
    "    c=0\n",
    "    \n",
    "    while c<10:\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        c+=1\n",
    "    time.sleep(1)\n",
    "    while c<10:\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_UP).perform()\n",
    "        c+=1\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if market !=\"San Antonio\":\n",
    "\n",
    "        targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[1]/div[2]/section/div[2]/section[2]/ol/li[1]/div[2]/div[2]/a')\n",
    "        targ.click()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[1]/div[2]/section/div[2]/section[2]/ol/li[2]/div[2]/div[2]/a')\n",
    "        targ.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[2]/div/div[2]/div/div[2]/button')\n",
    "        targ.click()\n",
    "    except:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('/html/body/div[9]/div[2]/div/div[1]/button/img').click()\n",
    "            targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[2]/div/div[2]/div/div[2]/button')\n",
    "            targ.click()\n",
    "        except:\n",
    "            driver.find_element_by_xpath('/html/body/div[10]/div[2]/div/div[1]/button/img').click()\n",
    "            targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[2]/div/div[2]/div/div[2]/button')\n",
    "            targ.click()\n",
    "        \n",
    "    summary=list()    \n",
    "    \n",
    "\n",
    "    brizand=(\"karbach\",\"shiner\",\"deep%20ellum\",\"blue%20moon\",\"saint%20arnold\",\"corona\",\"michelob%20ultra\",\"truly\",\"white%20claw\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for b in brizand:\n",
    "        suburl=\"https://www.totalwine.com/search/all?text=\"+b+\"&pageSize=72&department=Beer\"\n",
    "        driver.get(suburl)\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "\n",
    "        price_selector = soup.find_all(class_='price__1JvDDp_x')\n",
    "        product= soup.find_all(class_='productCard__2nWxIKmi')\n",
    "\n",
    "        price=[]\n",
    "        for i in price_selector:\n",
    "            price.append(str(re.findall(r'\\$[0-9.]*',str(i))[0]))\n",
    "\n",
    "\n",
    "        brand=[]\n",
    "        for i in product:\n",
    "            brand.append(str(re.findall(r'true\">[A-Za-z \\-]*[^\\<]',str(i))[0])[6:])\n",
    "\n",
    "        pkg= []\n",
    "        for i in product:\n",
    "                L=len(str(re.findall(r'<span>.*?\\<',str(i))[0]))\n",
    "                pkg.append(str(re.findall(r'<span>.*?\\<',str(i))[0][6:L-1])) \n",
    "\n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(pkg)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"Total Wine\",\"market\":market,\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "        \n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "cities=[\"San Antonio\",\"Austin\",\"Dallas\",\"Houston\",\"Corpus Christi\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(twscrape(i))\n",
    "     \n",
    "driver.close()\n",
    "\n",
    "filename=Current_Date+\"tw.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 24, 24]\n",
      "[21, 21, 21]\n",
      "[0, 0, 0]\n",
      "[8, 8, 8]\n",
      "[20, 20, 20]\n",
      "[18, 18, 17]\n",
      "[19, 19, 19]\n",
      "[10, 10, 9]\n",
      "[16, 16, 16]\n",
      "[4, 4, 4]\n",
      "[23, 23, 23]\n",
      "[10, 10, 10]\n",
      "[7, 7, 7]\n",
      "[3, 3, 3]\n",
      "[19, 19, 18]\n",
      "[18, 18, 18]\n",
      "[14, 14, 14]\n",
      "[21, 21, 21]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Kroger\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    " \n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "\n",
    "\n",
    "def krogerscrape(market):\n",
    "    login=market+\"31415@gmail.com\"\n",
    "    pw=market+\"31415!!\"\n",
    "    \n",
    "    #driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "\n",
    "    driver.get(\"https://www.kroger.com/signin?redirectUrl=/\")\n",
    "    \n",
    "    time.sleep(4)\n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"SignIn-emailInput\"]').send_keys(login)\n",
    "    driver.find_element_by_xpath('//*[@id=\"SignIn-passwordInput\"]').send_keys(pw)\n",
    "    driver.find_element_by_xpath('//*[@id=\"SignIn-submitButton\"]').click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    time.sleep(8)\n",
    "                   \n",
    "\n",
    "    brizand=(\"karbach\",\"shiner\",\"deep%20ellum\",\"blue%20moon\",\"saint%20arnold\",\"corona\",\"michelob%20ultra\",\"truly\",\"white%20claw\")\n",
    "        \n",
    "    summary=list()\n",
    "    \n",
    "    for b in brizand:\n",
    "        suburl=\"https://www.kroger.com/search?query=\"+b+\"%20beer&searchType=default_search&fulfillment=all\"\n",
    "        driver.get(suburl)\n",
    "        #WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"content\"]/div/div/div/div[2]/div[2]/div[3]/div/div/div/div[1]')))\n",
    "        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"content\"]/div/div/div/div[2]/div[2]/div[3]/div/div/div/div[1]')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "        \n",
    "        product= soup.find_all(class_='AutoGrid-cell min-w-0')\n",
    "        price_selector= soup.find_all(typeof=\"Price\")    \n",
    "        \n",
    "                \n",
    "        price=[]\n",
    "        for i in price_selector:\n",
    "            \n",
    "            L=len(str(re.findall(r'value=\"[0-9.].+meta',str(i))[0]))\n",
    "            price.append(str(re.findall(r'value=\"[0-9.].+meta',str(i))[0])[7:L-7])\n",
    "        \n",
    "        pkg= []\n",
    "        brand=[]\n",
    "        for i in product:\n",
    "            try:\n",
    "                L=len(str(re.findall(r'description\".*?-',str(i))[0]))\n",
    "                brand.append(str(re.findall(r'description\".*?-',str(i))[0])[13:L-2])\n",
    "                L=len(str(re.findall(r'description\".*?-',str(i))[0]))+1\n",
    "                pkg.append(str(re.findall(r'description\".*?h3',str(i))[0])[L:-4])\n",
    "\n",
    "            except:\n",
    "                brand.append('NA')\n",
    "                pkg.append('NA')\n",
    "                continue\n",
    "                \n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "\n",
    "        \n",
    "        for i in range(len(price)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"Kroger\",\"market\":market.capitalize(),\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "        \n",
    "    driver.close()\n",
    "    return summary\n",
    "           \n",
    "\n",
    "#cities=[\"San Angelo\",\"Houston\",\"San Antonio\",\"Austin\",\"Corpus Christi\",\"College Station\",\"Waco\",\"Victoria\",\"Mcallen\"]\n",
    "cities=[\"houston\",\"Dallas\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(krogerscrape(i))\n",
    "    \n",
    "\n",
    "\n",
    "filename=Current_Date+\"kroger.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 11, 11]\n",
      "[29, 29, 29]\n",
      "[10, 10, 10]\n",
      "[7, 7, 7]\n",
      "[2, 2, 2]\n",
      "[26, 26, 26]\n",
      "[24, 25, 24]\n",
      "[19, 19, 19]\n",
      "[19, 19, 19]\n",
      "[22, 22, 22]\n",
      "[25, 25, 25]\n",
      "[0, 0, 0]\n",
      "[9, 9, 9]\n",
      "[13, 13, 13]\n",
      "[20, 20, 20]\n",
      "[21, 21, 21]\n",
      "[15, 15, 15]\n",
      "[14, 14, 14]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Albertsons Randalls Tom Thumb\n",
    "\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "\n",
    "mlookup={\"Dallas\":\"75001\",\"Houston\":\"77001\"}\n",
    "\n",
    "\n",
    "def randyscrape(market):\n",
    "    \n",
    "    def clickit(xxpath):\n",
    "            tries=0\n",
    "            while tries<3:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, xxpath)))\n",
    "                    driver.find_element_by_xpath(xxpath).click()\n",
    "                    time.sleep(2)\n",
    "                    break\n",
    "                except:\n",
    "                    tries+=1   \n",
    "    def hoverclick(xxpath):\n",
    "        hover = ActionChains(driver).move_to_element(driver.find_element_by_xpath(xxpath))\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "\n",
    "        tries=0\n",
    "        while tries<3:\n",
    "            try:\n",
    "                hover.perform()\n",
    "                break\n",
    "            except:\n",
    "                tries+=1\n",
    "        time.sleep(2)\n",
    "        \n",
    "        action.click()\n",
    "        action.perform()\n",
    "        \n",
    "    def randyzip(xxpath):\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "        el=driver.find_element_by_xpath(xxpath)\n",
    "        action.move_to_element_with_offset(el,420,200)\n",
    "        action.click()\n",
    "        action.perform()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "    \n",
    "    url=\"https://www.albertsons.com\"\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    hoverclick(\"/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/div/div[2]/div[2]/div/div[2]/div[2]/button[3]/span/span[3]\")\n",
    "    \n",
    "    #Change zip code\n",
    "        \n",
    "    \n",
    "    hoverclick(\"/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input\")\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input').send_keys(mlookup[market])\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input').send_keys(Keys.ENTER)\n",
    "\n",
    "    randyzip('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input')\n",
    "    randyzip('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input')\n",
    "\n",
    "    \n",
    "    summary=list()    \n",
    "    \n",
    "    \n",
    "    brizand=(\"Karbach\",\"Shiner\",\"Deep Ellum\",\"Blue Moon\",\"Saint Arnold\",\"Corona\",\"Michelob Ultra\",\"Truly\",\"White Claw\")\n",
    "        \n",
    "    for b in brizand:\n",
    "        \n",
    "        k=b+\" beer\"\n",
    "        searchbar=driver.find_element_by_xpath(\"/html/body/div[2]/div/div/div[1]/div/div/div/div/div[3]/div[2]/div[6]/form/div/div/input\")\n",
    "        for L in range(20):\n",
    "            searchbar.send_keys(Keys.DELETE)\n",
    "            searchbar.send_keys(Keys.BACKSPACE)\n",
    "        searchbar.send_keys(k)\n",
    "        searchbar.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        c=0\n",
    "        while c<10:\n",
    "            ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "            c+=1\n",
    "        time.sleep(1)\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_UP).perform()\n",
    "        \n",
    "        #driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        #time.sleep(5)\n",
    "        #html_content = driver.execute_script('return document.body.innerHTML')\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        #soup = BeautifulSoup(html_content, 'lxml')\n",
    "        soup = BeautifulSoup(page_source)\n",
    "\n",
    "        product= soup.body.find_all(class_='ab-lazy loaded')\n",
    "        price_selector = soup.find_all(class_='product-price-con')\n",
    "        \n",
    "        \n",
    "        price=[]\n",
    "        brand=[]\n",
    "        pkg=[]\n",
    "        \n",
    "        for pr,br in zip(price_selector,product):\n",
    "                 \n",
    "            try:\n",
    "                brand.append(str(re.findall(rf'{b}.*? -',str(br))[0])[:-2])\n",
    "                pkg.append(str(re.findall(r'- .*?(?:Oz|FZ)',str(br))[0][2:]))\n",
    "                price.append(str(re.findall(r'Your Price.*?\\$[0-9.]*',str(pr))[0][18:]))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "        \n",
    "        for i in range(len(pkg)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"Albertsons Network\",\"market\":market,\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "        \n",
    "        \n",
    "    driver.close()       \n",
    "    return summary\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "cities=[\"Dallas\",\"Houston\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(randyscrape(i))\n",
    "     \n",
    "\n",
    "\n",
    "filename=Current_Date+\"albert.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McAllen\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Walmart\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    " \n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "mlookup={\"Dallas\":\"75001\",\"San Angelo\":\"76901\",\"Houston\":\"77001\",\"San Antonio\":\"78232\",\n",
    "         \"Austin\":\"73301\",\"Corpus Christi\":\"78336\",\"College Station\":\"77802\",\"Waco\":\"76633\",\n",
    "         \"Victoria\":\"77901\",\"McAllen\":\"78501\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wmscrape(market):\n",
    "    print(market)\n",
    "    def clickit(xxpath):\n",
    "            tries=0\n",
    "            while tries<3:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, xxpath)))\n",
    "                    driver.find_element_by_xpath(xxpath).click()\n",
    "                    time.sleep(2)\n",
    "                    break\n",
    "                except:\n",
    "                    tries+=1   \n",
    "    def hoverclick(xxpath):\n",
    "        hover = ActionChains(driver).move_to_element(driver.find_element_by_xpath(xxpath))\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "\n",
    "        tries=0\n",
    "        while tries<3:\n",
    "            try:\n",
    "                hover.perform()\n",
    "                break\n",
    "            except:\n",
    "                tries+=1\n",
    "        time.sleep(2)\n",
    "        \n",
    "        action.click()\n",
    "        action.perform()\n",
    "        \n",
    "    def randyzip(xxpath):\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "        el=driver.find_element_by_xpath(xxpath)\n",
    "        action.move_to_element_with_offset(el,420,200)\n",
    "        action.click()\n",
    "        action.perform()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    \n",
    "    login=market.lower()+\"31415@gmail.com\"\n",
    "    pw=market.lower()+\"31415!!\"\n",
    "    \n",
    "    url=\"https://www.walmart.com\"\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Change zip code\n",
    "            \n",
    "    hoverclick(\"/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[2]/div/div[1]/div[1]/button/span/img\")\n",
    "    hoverclick(\"/html/body/div[1]/div/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[2]/div[2]/div[3]/button/span\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[3]/div/div[2]/form/div[1]/input').send_keys(Keys.BACKSPACE)\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[3]/div/div[2]/form/div[1]/input').send_keys(Keys.BACKSPACE)\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[3]/div/div[2]/form/div[1]/input').send_keys(Keys.BACKSPACE)\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[3]/div/div[2]/form/div[1]/input').send_keys(Keys.BACKSPACE)\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[3]/div/div[2]/form/div[1]/input').send_keys(Keys.BACKSPACE)\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[3]/div/div[2]/form/div[1]/input').send_keys(mlookup[market])\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/div[1]/section/section/div[2]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[3]/div/div[2]/form/div[1]/input').send_keys(Keys.ENTER)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    summary=list()    \n",
    "    \n",
    "\n",
    "    brizand=(\"Shiner\",\"Karbach\",\"Deep Ellum\",\"Blue Moon\",\"Saint Arnold\",\"Corona\",\"Michelob Ultra\",\"Truly\",\"White Claw\")\n",
    "        \n",
    "    for b in brizand:\n",
    "        \n",
    "        k=b+\" beer\"\n",
    "        searchbar=driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/section/section/div[2]/div/div[3]/div[2]/div/form/input[2]\")\n",
    "        if b != \"Shiner\":\n",
    "\n",
    "            for L in range(60):\n",
    "                searchbar.send_keys(Keys.DELETE)\n",
    "                \n",
    "            for L in range(60):\n",
    "                \n",
    "                searchbar.send_keys(Keys.BACKSPACE)\n",
    "        \n",
    "        searchbar.send_keys(k)\n",
    "        searchbar.send_keys(Keys.ENTER)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        \n",
    "        tiles = driver.find_elements_by_class_name(\"orientation-square\")\n",
    "        wrongproduct=0\n",
    "        for t in range(len(tiles)):\n",
    "            tiles1 = driver.find_elements_by_class_name(\"orientation-square\")\n",
    "            \n",
    "            if wrongproduct>1:\n",
    "                break\n",
    "            \n",
    "            tiles1[t].click()\n",
    "            time.sleep(3)\n",
    "            \n",
    "            \n",
    "            page_source = driver.page_source\n",
    "            #soup = BeautifulSoup(html_content, 'lxml')\n",
    "            soup = BeautifulSoup(page_source)\n",
    "                        \n",
    "            product= soup.body.find_all(class_='prod-ProductTitle prod-productTitle-buyBox font-bold')\n",
    "            price_selector = soup.find_all(class_='price display-inline-block arrange-fit price')\n",
    "\n",
    "            \n",
    "            for i in range(len(product)):\n",
    "                try:\n",
    "                    \n",
    "                    \n",
    "                    if len(re.findall(rf'{b}.*?\\\"',str(product[i])))==0:\n",
    "                        wrongproduct+=1\n",
    "                        \n",
    "                        continue\n",
    "                    \n",
    "                    price=[]\n",
    "                    brand=[]\n",
    "                    pkg= []\n",
    "\n",
    "                    price.append(str(re.findall(r'\\$[0-9.]*',str(price_selector[i]))[0]))\n",
    "\n",
    "                    brand.append(str(re.findall(rf'{b}.*?(?:,|[0-9])',str(product[i]))[0])[:-1])\n",
    "                    L=len(re.findall(rf'{b}.*?(?:\\,|[0-9])',str(product[i]))[0])-1\n",
    "\n",
    "                    pkg.append(str(re.findall(rf'{b}.*?\\\"',str(product[i]))[0])[L:])\n",
    "\n",
    "                    \n",
    "                    print([len(pkg),len(brand),len(price)])\n",
    "                    \n",
    "                    summary.append({\"cdate\":Current_Date,\"store\":\"Walmart\",\"market\":market,\"pkg\":pkg[0],\"brand\":brand[0],\"price\":price[0]})\n",
    "\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "          \n",
    "            \n",
    "            \n",
    "            driver.back()\n",
    "            time.sleep(3)\n",
    "            \n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "           \n",
    "\n",
    "#cities=[\"Dallas\",\"San Angelo\",\"Houston\",\"San Antonio\",\"Austin\",\"Corpus Christi\",\"College Station\",\"Waco\",\"Victoria\",\"McAllen\"]\n",
    "cities=[\"Austin\",\"Corpus Christi\",\"College Station\",\"Waco\",\"Dallas\",\"San Angelo\",\"Houston\",\"San Antonio\",\"Victoria\",\"McAllen\"]\n",
    "#\n",
    "Combined = list()\n",
    "\n",
    "trock=0\n",
    "\n",
    "for i in cities:\n",
    "    while True:\n",
    "    \n",
    "        try:\n",
    "            Combined.append(wmscrape(i))\n",
    "            break\n",
    "        except:\n",
    "            print(\"Fail\")\n",
    "            driver.close()\n",
    "            driver = webdriver.Chrome(executable_path=r'C:\\Users\\MGrogan\\Documents\\People\\todd\\chromedriver.exe', options=options)\n",
    "\n",
    "driver.close()\n",
    "    \n",
    "filename=Current_Date+\"wm.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
