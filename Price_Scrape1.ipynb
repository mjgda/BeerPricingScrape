{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment for when Chrome version changes\n",
    "\n",
    "#from selenium import webdriver\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HEB\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "#Driver settings\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    " \n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "\n",
    "#To get around javascript barriers in HEB website, there is a seperate account for each metro area where the zipcode is \n",
    "#preset for that account. HEB uses extensive bot prevention measures, and each login requires passing several CAPTCHA \n",
    "#tests, but even with those extra steps the data collection is much faster. Short forms of cities are used in the \n",
    "#lookup below for the email addresses and the long forms are used in the final output.\n",
    "\n",
    "mlookup={\"angelo\":\"San Angelo\",\"htx\":\"Houston\",\"sa\":\"San Antonio\",\"atx\":\"Austin\",\"cc\":\"Corpus Christi\",\"colleges\":\"College Station\",\"waco\":\"Waco\",\"victoria\":\"Victoria\",\"mcallen\":\"McAllen\"}\n",
    "\n",
    "def hebscrape(market):\n",
    "    login=market+\"price31415@gmail.com\"\n",
    "    pw=market+\"price31415!!\"\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path=r'./chromedriver.exe', options=options)\n",
    "\n",
    "    driver.get(\"https://www.heb.com/my-account/login?originalURL=https%3A%2F%2Fwww.heb.com%2Fmy-account%2Fdash-board\")\n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"email\"]').send_keys(login)\n",
    "    driver.find_element_by_xpath('//*[@id=\"password\"]').send_keys(pw)\n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"loginForm\"]/form/div[4]/div/button/span').click()\n",
    "    WebDriverWait(driver, 600).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"root\"]/header/div[1]/div[2]/div[1]/form/div/input')))\n",
    "    \n",
    "    #Rather than utilizing search bar, you can go to the webaddress associated with that search query\n",
    "                       \n",
    "    brizand=(\"Karbach\",\"Shiner\",\"Deep Ellum\",\"Blue Moon\",\"Saint Arnold\",\"Corona\",\"Michelob Ultra\",\"Truly\",\"White Claw\")\n",
    "    summary=list()\n",
    "    \n",
    "    \n",
    "    for b in brizand:\n",
    "        suburl=\"https://www.heb.com/search/?q=\"+b+\"+beer\"\n",
    "        driver.get(suburl)\n",
    "        time.sleep(7)\n",
    "               \n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "        \n",
    "        #Some cities have different versions of the HEB website, so there are different tags\n",
    "        #for the tiles that have the product information. If the first doesn't work then the second\n",
    "        #one will.\n",
    "\n",
    "        if len(soup.find_all(class_='sc-ztn198-0 jQudBd sc-cltr8j-0 fNTXmj'))>0:\n",
    "            product= soup.find_all(class_='sc-ztn198-0 jQudBd sc-cltr8j-0 fNTXmj')            \n",
    "            \n",
    "            price=[]\n",
    "            pkg= []\n",
    "            brand=[]\n",
    "            for i in product:\n",
    "                try:\n",
    "\n",
    "                    title=str(re.findall(rf'aria-label=\\\"{b}.+?each\\.',str(i))[0])\n",
    "                    title=title[12:]\n",
    "                    title=title.split(',')\n",
    "                    \n",
    "                    brand.append(title[0])\n",
    "                    price.append(title[1][:-5].strip())\n",
    "                    \n",
    "                    \n",
    "                    title2=str(re.findall(rf'alt=\\\"{b}.+?\\\"',str(i))[0])\n",
    "                    title2=title2.split(',')\n",
    "                    pkg.append(title2[1][1:])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "\n",
    "        else:\n",
    "            price_selector = soup.find_all(class_='cat-price-number')\n",
    "            product= soup.find_all(class_='responsivegriditem product-grid-large-fifth product-grid-small-6')\n",
    "\n",
    "            if len(product)==0:\n",
    "                product= soup.find_all(class_='ztn198-0 gIcCcD cltr8j-0 jfvaNx')\n",
    "\n",
    "\n",
    "            price=[]\n",
    "            for i in price_selector:\n",
    "                price.append(str(re.findall(r'\\$[0-9.]*',str(i))[0]))\n",
    "\n",
    "            pkg= []\n",
    "            brand=[]\n",
    "            for i in product:\n",
    "                L=len(str(re.findall(rf'aria-label=\\\"{b}.*[^\\$]',str(i))))\n",
    "                brand.append(str(re.findall(rf'aria-label=\\\"{b}.*[^\\$]',str(i)))[14:L-6])\n",
    "                L=len(str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i))))\n",
    "                tes=str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i)))[L-8:L-2]\n",
    "\n",
    "                if tes[0]!='t':\n",
    "                    pkg.append(str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i)))[L-8:L-2])\n",
    "                else:\n",
    "                    pkg.append(str(re.findall(rf'aria-label=\\\"{b}.*\\n*\\t*\\t*.......',str(i)))[L-7:L-2])\n",
    "\n",
    "                   \n",
    "        #Make sure that there are an equal number of prices, brand names, and product types for each brand\n",
    "        \n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "        for i in range(len(pkg)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"HEB\",\"market\":mlookup[market],\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "\n",
    "    driver.close()\n",
    "    return summary\n",
    "         \n",
    "\n",
    "cities=[\"angelo\",\"htx\",\"sa\",\"atx\",\"cc\",\"colleges\",\"waco\",\"victoria\",\"mcallen\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(hebscrape(i))\n",
    "\n",
    "\n",
    "filename=Current_Date+\"heb.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Total Wine\n",
    "\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def twscrape(market):\n",
    "    \n",
    "    def hoverclick(xxpath):\n",
    "        hover = ActionChains(driver).move_to_element(driver.find_element_by_xpath(xxpath))\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "\n",
    "        tries=0\n",
    "        while tries<3:\n",
    "            try:\n",
    "                hover.perform()\n",
    "                break\n",
    "            except:\n",
    "                tries+=1\n",
    "        time.sleep(2)\n",
    "        \n",
    "        action.click()\n",
    "        action.perform()\n",
    "    \n",
    "    url=\"https://www.totalwine.com/store-finder/search?q=\"+market.replace(\" \",\"%20\")+\"&radius=15\"\n",
    "    driver.get(url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "    try:\n",
    "        hoverclick('/html/body/div[9]/div[2]/div/button')\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        time.sleep(2)\n",
    "    \n",
    "    c=0\n",
    "    \n",
    "    while c<10:\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        c+=1\n",
    "    time.sleep(1)\n",
    "    while c<10:\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_UP).perform()\n",
    "        c+=1\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if market !=\"San Antonio\":\n",
    "\n",
    "        targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[1]/div[2]/section/div[2]/section[2]/ol/li[1]/div[2]/div[2]/a')\n",
    "        targ.click()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[1]/div[2]/section/div[2]/section[2]/ol/li[2]/div[2]/div[2]/a')\n",
    "        targ.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[2]/div/div[2]/div/div[2]/button')\n",
    "        targ.click()\n",
    "    except:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('/html/body/div[9]/div[2]/div/div[1]/button/img').click()\n",
    "            targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[2]/div/div[2]/div/div[2]/button')\n",
    "            targ.click()\n",
    "        except:\n",
    "            driver.find_element_by_xpath('/html/body/div[10]/div[2]/div/div[1]/button/img').click()\n",
    "            targ=driver.find_element_by_xpath('/html/body/div[1]/div/div/main/div/div[2]/div/div[2]/div/div[2]/button')\n",
    "            targ.click()\n",
    "        \n",
    "    summary=list()    \n",
    "    \n",
    "\n",
    "    brizand=(\"karbach\",\"shiner\",\"deep%20ellum\",\"blue%20moon\",\"saint%20arnold\",\"corona\",\"michelob%20ultra\",\"truly\",\"white%20claw\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for b in brizand:\n",
    "        suburl=\"https://www.totalwine.com/search/all?text=\"+b+\"&pageSize=72&department=Beer\"\n",
    "        driver.get(suburl)\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "\n",
    "        price_selector = soup.find_all(class_='price__1JvDDp_x')\n",
    "        product= soup.find_all(class_='productCard__2nWxIKmi')\n",
    "\n",
    "        price=[]\n",
    "        for i in price_selector:\n",
    "            price.append(str(re.findall(r'\\$[0-9.]*',str(i))[0]))\n",
    "\n",
    "\n",
    "        brand=[]\n",
    "        for i in product:\n",
    "            brand.append(str(re.findall(r'true\">[A-Za-z \\-]*[^\\<]',str(i))[0])[6:])\n",
    "\n",
    "        pkg= []\n",
    "        for i in product:\n",
    "                L=len(str(re.findall(r'<span>.*?\\<',str(i))[0]))\n",
    "                pkg.append(str(re.findall(r'<span>.*?\\<',str(i))[0][6:L-1])) \n",
    "\n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(pkg)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"Total Wine\",\"market\":market,\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "        \n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=r'./chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "cities=[\"San Antonio\",\"Austin\",\"Dallas\",\"Houston\",\"Corpus Christi\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(twscrape(i))\n",
    "     \n",
    "driver.close()\n",
    "\n",
    "filename=Current_Date+\"tw.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Kroger\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    " \n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "\n",
    "\n",
    "def krogerscrape(market):\n",
    "    login=market+\"31415@gmail.com\"\n",
    "    pw=market+\"31415!!\"\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path=r'./chromedriver.exe', options=options)\n",
    "\n",
    "    driver.get(\"https://www.kroger.com/signin?redirectUrl=/\")\n",
    "    \n",
    "    time.sleep(4)\n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"SignIn-emailInput\"]').send_keys(login)\n",
    "    driver.find_element_by_xpath('//*[@id=\"SignIn-passwordInput\"]').send_keys(pw)\n",
    "    driver.find_element_by_xpath('//*[@id=\"SignIn-submitButton\"]').click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    time.sleep(8)\n",
    "                   \n",
    "\n",
    "    brizand=(\"karbach\",\"shiner\",\"deep%20ellum\",\"blue%20moon\",\"saint%20arnold\",\"corona\",\"michelob%20ultra\",\"truly\",\"white%20claw\")\n",
    "        \n",
    "    summary=list()\n",
    "    \n",
    "    for b in brizand:\n",
    "        suburl=\"https://www.kroger.com/search?query=\"+b+\"%20beer&searchType=default_search&fulfillment=all\"\n",
    "        driver.get(suburl)\n",
    "        #WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"content\"]/div/div/div/div[2]/div[2]/div[3]/div/div/div/div[1]')))\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"content\"]/div/div/div/div[2]/div[2]/div[3]/div/div/div/div[1]')))\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "        \n",
    "        product= soup.find_all(class_='AutoGrid-cell min-w-0')\n",
    "        price_selector= soup.find_all(typeof=\"Price\")    \n",
    "        \n",
    "                \n",
    "        price=[]\n",
    "        for i in price_selector:\n",
    "            \n",
    "            L=len(str(re.findall(r'value=\"[0-9.].+meta',str(i))[0]))\n",
    "            price.append(str(re.findall(r'value=\"[0-9.].+meta',str(i))[0])[7:L-7])\n",
    "        \n",
    "        pkg= []\n",
    "        brand=[]\n",
    "        for i in product:\n",
    "            try:\n",
    "                L=len(str(re.findall(r'description\".*?-',str(i))[0]))\n",
    "                brand.append(str(re.findall(r'description\".*?-',str(i))[0])[13:L-2])\n",
    "                L=len(str(re.findall(r'description\".*?-',str(i))[0]))+1\n",
    "                pkg.append(str(re.findall(r'description\".*?h3',str(i))[0])[L:-4])\n",
    "\n",
    "            except:\n",
    "                brand.append('NA')\n",
    "                pkg.append('NA')\n",
    "                continue\n",
    "                \n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "\n",
    "        \n",
    "        for i in range(len(price)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"Kroger\",\"market\":market.capitalize(),\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "        \n",
    "    driver.close()\n",
    "    return summary\n",
    "           \n",
    "\n",
    "#cities=[\"San Angelo\",\"Houston\",\"San Antonio\",\"Austin\",\"Corpus Christi\",\"College Station\",\"Waco\",\"Victoria\",\"Mcallen\"]\n",
    "cities=[\"houston\",\"Dallas\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(krogerscrape(i))\n",
    "    \n",
    "\n",
    "\n",
    "filename=Current_Date+\"kroger.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Albertsons Randalls Tom Thumb\n",
    "\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "\n",
    "mlookup={\"Dallas\":\"75001\",\"Houston\":\"77001\"}\n",
    "\n",
    "\n",
    "def randyscrape(market):\n",
    "    \n",
    "    def clickit(xxpath):\n",
    "            tries=0\n",
    "            while tries<3:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, xxpath)))\n",
    "                    driver.find_element_by_xpath(xxpath).click()\n",
    "                    time.sleep(2)\n",
    "                    break\n",
    "                except:\n",
    "                    tries+=1   \n",
    "    def hoverclick(xxpath):\n",
    "        hover = ActionChains(driver).move_to_element(driver.find_element_by_xpath(xxpath))\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "\n",
    "        tries=0\n",
    "        while tries<3:\n",
    "            try:\n",
    "                hover.perform()\n",
    "                break\n",
    "            except:\n",
    "                tries+=1\n",
    "        time.sleep(2)\n",
    "        \n",
    "        action.click()\n",
    "        action.perform()\n",
    "        \n",
    "    def randyzip(xxpath):\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "        el=driver.find_element_by_xpath(xxpath)\n",
    "        action.move_to_element_with_offset(el,420,200)\n",
    "        action.click()\n",
    "        action.perform()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path=r'./chromedriver.exe', options=options)\n",
    "    \n",
    "    url=\"https://www.albertsons.com\"\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    hoverclick(\"/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/div/div[2]/div[2]/div/div[2]/div[2]/button[3]/span/span[3]\")\n",
    "    \n",
    "    #Change zip code\n",
    "        \n",
    "    \n",
    "    hoverclick(\"/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input\")\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input').send_keys(mlookup[market])\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input').send_keys(Keys.ENTER)\n",
    "\n",
    "    randyzip('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input')\n",
    "    randyzip('/html/body/div[2]/div/div/div[3]/div/div/div/div/div[2]/store-fulfillment-modal-unified/div/div/div/div[2]/store-fulfillment-tabs/div/div[1]/input')\n",
    "\n",
    "    \n",
    "    summary=list()    \n",
    "    \n",
    "    \n",
    "    brizand=(\"Karbach\",\"Shiner\",\"Deep Ellum\",\"Blue Moon\",\"Saint Arnold\",\"Corona\",\"Michelob Ultra\",\"Truly\",\"White Claw\")\n",
    "        \n",
    "    for b in brizand:\n",
    "        \n",
    "        k=b+\" beer\"\n",
    "        searchbar=driver.find_element_by_xpath(\"/html/body/div[2]/div/div/div[1]/div/div/div/div/div[3]/div[2]/div[6]/form/div/div/input\")\n",
    "        for L in range(20):\n",
    "            searchbar.send_keys(Keys.DELETE)\n",
    "            searchbar.send_keys(Keys.BACKSPACE)\n",
    "        searchbar.send_keys(k)\n",
    "        searchbar.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        c=0\n",
    "        while c<10:\n",
    "            ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "            c+=1\n",
    "        time.sleep(1)\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_UP).perform()\n",
    "        \n",
    "        #driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        #time.sleep(5)\n",
    "        #html_content = driver.execute_script('return document.body.innerHTML')\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        #soup = BeautifulSoup(html_content, 'lxml')\n",
    "        soup = BeautifulSoup(page_source)\n",
    "\n",
    "        product= soup.body.find_all(class_='ab-lazy loaded')\n",
    "        price_selector = soup.find_all(class_='product-price-con')\n",
    "        \n",
    "        \n",
    "        price=[]\n",
    "        brand=[]\n",
    "        pkg=[]\n",
    "        \n",
    "        for pr,br in zip(price_selector,product):\n",
    "                 \n",
    "            try:\n",
    "                brand.append(str(re.findall(rf'{b}.*? -',str(br))[0])[:-2])\n",
    "                pkg.append(str(re.findall(r'- .*?(?:Oz|FZ)',str(br))[0][2:]))\n",
    "                price.append(str(re.findall(r'Your Price.*?\\$[0-9.]*',str(pr))[0][18:]))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "        \n",
    "        for i in range(len(pkg)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"Albertsons Network\",\"market\":market,\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "        \n",
    "        \n",
    "    driver.close()       \n",
    "    return summary\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=r'./chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "cities=[\"Dallas\",\"Houston\"]\n",
    "\n",
    "Combined = list()\n",
    "\n",
    "for i in cities:\n",
    "    Combined.append(randyscrape(i))\n",
    "     \n",
    "\n",
    "\n",
    "filename=Current_Date+\"albert.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "##Walmart\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\")\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_settings.cookies\": 3})    \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    " \n",
    "\n",
    "Current_Date = datetime.datetime.today().strftime ('%m%d%Y')\n",
    "\n",
    "mlookup={\"Dallas\":\"75001\",\"San Angelo\":\"76901\",\"Houston\":\"77001\",\"San Antonio\":\"78232\",\n",
    "         \"Austin\":\"73301\",\"Corpus Christi\":\"78336\",\"College Station\":\"77802\",\"Waco\":\"76633\",\n",
    "         \"Victoria\":\"77901\",\"McAllen\":\"78501\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wmscrape(market):\n",
    "    print(market)\n",
    "    def clickit(xxpath):\n",
    "            tries=0\n",
    "            while tries<3:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, xxpath)))\n",
    "                    driver.find_element_by_xpath(xxpath).click()\n",
    "                    time.sleep(2)\n",
    "                    break\n",
    "                except:\n",
    "                    tries+=1   \n",
    "    def hoverclick(xxpath):\n",
    "        hover = ActionChains(driver).move_to_element(driver.find_element_by_xpath(xxpath))\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "\n",
    "        tries=0\n",
    "        while tries<3:\n",
    "            try:\n",
    "                hover.perform()\n",
    "                break\n",
    "            except:\n",
    "                tries+=1\n",
    "        time.sleep(2)\n",
    "        \n",
    "        action.click()\n",
    "        action.perform()\n",
    "        \n",
    "    def randyzip(xxpath):\n",
    "        action = webdriver.common.action_chains.ActionChains(driver)\n",
    "        el=driver.find_element_by_xpath(xxpath)\n",
    "        action.move_to_element_with_offset(el,10,10)\n",
    "        action.click()\n",
    "        action.perform()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    \n",
    "    login=market.lower()+\"31415@gmail.com\"\n",
    "    pw=market.lower()+\"31415!!\"\n",
    "    \n",
    "    url=\"https://www.walmart.com\"\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Change zip code\n",
    "    hoverclick(\"/html/body/div/div[1]/div/div/div/section/div/button[2]\")\n",
    "    time.sleep(2)\n",
    "    randyzip(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/form/div/label/span\")\n",
    "    #randyzip(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/section/form/div/div/input\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    actions = ActionChains(driver)\n",
    "    actions.send_keys(Keys.DELETE)\n",
    "    actions.send_keys(Keys.DELETE)\n",
    "    actions.send_keys(Keys.DELETE)\n",
    "    actions.send_keys(Keys.DELETE)\n",
    "    actions.send_keys(Keys.DELETE)\n",
    "    actions.send_keys(Keys.DELETE)\n",
    "    \n",
    "    \n",
    "    actions.send_keys(mlookup[market])\n",
    "    actions.perform()\n",
    "    actions.send_keys(Keys.ENTER)\n",
    "    actions.perform()\n",
    "    \n",
    "    #driver.find_element_by_xpath(\"/html/body/div[2]/div/div[3]/div[1]/div/div[2]/div/form/div/div/input\").send_keys(Keys.BACKSPACE)\n",
    "    #print(\"wtf\")\n",
    "    #driver.find_element_by_xpath(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/form/div/div/input\").send_keys(Keys.BACKSPACE)\n",
    "    #driver.find_element_by_xpath(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/form/div/div/input\").send_keys(Keys.BACKSPACE)\n",
    "    #driver.find_element_by_xpath(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/form/div/div/input\").send_keys(Keys.BACKSPACE)\n",
    "    #driver.find_element_by_xpath(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/form/div/div/input\").send_keys(Keys.BACKSPACE)\n",
    "    #driver.find_element_by_xpath(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/form/div/div/input\").send_keys(mlookup[market])\n",
    "    #driver.find_element_by_xpath(\"/html/body/div[3]/div/div[3]/div[1]/div/div[2]/div/form/div/div/input\").send_keys(Keys.ENTER)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    summary=list()    \n",
    "    \n",
    "\n",
    "    brizand=(\"Shiner\",\"Karbach\",\"Deep Ellum\",\"Blue Moon\",\"Saint Arnold\",\"Corona\",\"Michelob Ultra\",\"Truly\",\"White Claw\")\n",
    "        \n",
    "    for b in brizand:\n",
    "        \n",
    "        k=b+\" beer\"\n",
    "        searchbar=driver.find_element_by_xpath(\"/html/body/div/div[1]/div/span/header/div/form/div/input\")\n",
    "        if b != \"Shiner\":\n",
    "\n",
    "            for L in range(60):\n",
    "                searchbar.send_keys(Keys.DELETE)\n",
    "                \n",
    "            for L in range(60):\n",
    "                \n",
    "                searchbar.send_keys(Keys.BACKSPACE)\n",
    "        \n",
    "        searchbar.send_keys(k)\n",
    "        searchbar.send_keys(Keys.ENTER)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(page_source)\n",
    "\n",
    "        product=[]\n",
    "        prices=[]\n",
    "        \n",
    "        wtflist=['w_Dr','w_DY','w_DP','w_Cj','w_D1']\n",
    "        merged= soup.body.find_all(class_='w_D1')\n",
    "        \n",
    "        for m in merged:\n",
    "            if b in str(m):\n",
    "                product.append(m)\n",
    "            elif \"current price\" in str(m):\n",
    "                prices.append(m)\n",
    "                \n",
    "            \n",
    "\n",
    "        price=[]\n",
    "        brand=[]\n",
    "        pkg=[]\n",
    "\n",
    "        for i in range(len(product)):\n",
    "            brand.append(str(re.search(r'\\>.*?(,|\\d)',str(product[i])).group(0))[1:-1])\n",
    "            \n",
    "            pkg.append(str(re.search(rf'\\d.*?(pack|Pack|pk|c|B|z|b|C)',str(product[i])).group(0)))\n",
    "            \n",
    "            price.append(str(re.findall(rf'\\$[0-9.]*',str(prices[i]))[0]))\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        print([len(pkg),len(brand),len(price)])\n",
    "        \n",
    "        \n",
    "        for i in range(len(pkg)):\n",
    "            summary.append({\"cdate\":Current_Date,\"store\":\"Walmart\",\"market\":market,\"pkg\":pkg[i],\"brand\":brand[i],\"price\":price[i]})\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        driver.back()\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=r'./chromedriver.exe', options=options)\n",
    "           \n",
    "\n",
    "#cities=[\"Dallas\",\"San Angelo\",\"Houston\",\"San Antonio\",\"Austin\",\"Corpus Christi\",\"College Station\",\"Waco\",\"Victoria\",\"McAllen\"]\n",
    "cities=[\"Austin\",\"Corpus Christi\",\"College Station\",\"Waco\",\"Dallas\",\"San Angelo\",\"Houston\",\"San Antonio\",\"Victoria\",\"McAllen\"]\n",
    "#\n",
    "Combined = list()\n",
    "\n",
    "\n",
    "\n",
    "for i in cities:\n",
    "    while True:\n",
    "        try:\n",
    "            Combined.append(wmscrape(i))\n",
    "            break\n",
    "        except:\n",
    "            print(\"Fail\")\n",
    "            driver.close()\n",
    "            driver = webdriver.Chrome(executable_path=r'./chromedriver.exe', options=options)\n",
    "\n",
    "driver.close()\n",
    "    \n",
    "filename=Current_Date+\"wm.json\"\n",
    "update=open(filename,'w')\n",
    "json.dump(Combined,update)\n",
    "update.close()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
